{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db00552d-c895-4b45-acab-970816b8f52e",
   "metadata": {},
   "source": [
    "# 7 · Recognition of a Universal Class\n",
    "\n",
    "**Observational record associated with the book**  \n",
    "*Discovering Chaos in Prime Numbers — Computational Investigations through the Euler Mirror*  \n",
    "© Alvaro Costa, 2025\n",
    "\n",
    "This notebook is part of a canonical sequence of computational records.  \n",
    "It introduces **no new hypotheses, conjectures, or interpretative models**.\n",
    "\n",
    "Its sole purpose is to **record** the behaviour of arithmetic structures under an explicit,  \n",
    "deterministic, and reproducible regime of observation.\n",
    "\n",
    "The complete conceptual discussion is presented in the book.  \n",
    "This notebook documents only the corresponding experiment.\n",
    "\n",
    "**Licence:** Creative Commons BY–NC–ND 4.0  \n",
    "Reading, execution, and citation are permitted.  \n",
    "Modification, derivative redistribution, or independent commercial use are not permitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4580edc-5a5e-4126-808b-2188825cf972",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. From Image to Sound: Measuring Harmony\n",
    "\n",
    "In the previous chapter, we witnessed a striking visual phenomenon: as the scale $ X_0 $ increases, the structure of our matrix $ M $ transitions  \n",
    "from apparently chaotic “noise” to a crystalline visual harmony. But what defines this harmony? How can we demonstrate that it is not merely an  \n",
    "optical artefact?\n",
    "\n",
    "To answer this, we must move from the “photograph” of the matrix to its “music”. In quantum physics and random matrix theory, the music of a system  \n",
    "is encoded in its **eigenvalue spectrum** — the fundamental frequencies at which the system resonates.\n",
    "\n",
    "In this chapter, we employ three statistical tools to analyse the spacings between these eigenvalues and to demonstrate that the music they produce  \n",
    "follows the universal score of the **Gaussian Orthogonal Ensemble (GOE)**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. The Tools of the Spectral Musicologist\n",
    "\n",
    "### a) The Spacing Distribution $ P(s) $: The Fingerprint\n",
    "\n",
    "The histogram of spacings between consecutive eigenvalues, normalised by their mean, constitutes the fingerprint of the system.\n",
    "\n",
    "* **Independent systems (Poisson):**  \n",
    "  Eigenvalues do not “care” about one another and may cluster freely. The highest probability is found at very small spacings, resulting in a monotonically  \n",
    "  decreasing exponential curve.\n",
    "\n",
    "* **Correlated systems (GOE):**\n",
    "  Eigenvalues repel one another; they actively avoid excessive proximity. The result is the celebrated **Wigner surmise**, a curve that  \n",
    "  vanishes at $ s = 0 $ (total level repulsion), rises to a maximum, and then decays smoothly.\n",
    "\n",
    "---\n",
    "\n",
    "### b) The $ \\langle r \\rangle $-mean: The Correlation Thermometer\n",
    "\n",
    "The $ \\langle r \\rangle $-mean is the average ratio of adjacent spacings. It is a scalar quantity that immediately indicates the regime in which the system  \n",
    "operates:\n",
    "\n",
    "* $ \\langle r \\rangle \\approx 0.386 $ indicates a **Poisson** system (no correlation).\n",
    "* $ \\langle r \\rangle \\approx 0.536 $ indicates a **GOE** system (maximal local correlation).\n",
    "\n",
    "To ensure statistical rigour, we employ the ***Moving Block Bootstrap* (MBB)** to compute a 95% confidence interval, allowing us to verify whether the  \n",
    "theoretical GOE value is statistically supported by the data.\n",
    "\n",
    "---\n",
    "\n",
    "### c) The Number Variance $ \\Sigma^2(L) $: The Rigidity Test\n",
    "\n",
    "This measure probes the long-range “memory” of the spectrum by quantifying the variance in the number of eigenvalues contained within spectral windows of  \n",
    "length $ L $.\n",
    "\n",
    "* **Poisson systems:**  \n",
    "  The spectrum is “soft”. The variance grows linearly with the window length ($ \\Sigma^2(L) \\approx L $).\n",
    "\n",
    "* **GOE systems:**  \n",
    "  The spectrum is “rigid”. Due to level repulsion, eigenvalues are distributed so uniformly that the variance grows only **logarithmically**\n",
    "  ($ \\Sigma^2(L) \\approx \\ln L $).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Interactive Laboratory: Listening to the Music of the Primes\n",
    "\n",
    "The code cell below implements these tools. Use the selectors to vary $ N $ and $ X_0 $ (values of $ X_0 \\ge 10^7 $ are recommended for a clear visualisation  \n",
    "of GOE emergence).\n",
    "\n",
    "**What to observe:**\n",
    "\n",
    "1. **In the $ P(s) $ plot:**  \n",
    "   Observe how the blue histogram departs from the green noise (Poisson) and “dresses itself” in the red curve (Wigner/GOE).\n",
    "\n",
    "2. **In the $ \\langle r \\rangle $-mean plot:**  \n",
    "   Note how the measured point aligns with the GOE reference value, supported by the confidence interval.\n",
    "\n",
    "3. **In the $ \\Sigma^2(L) $ plot:**  \n",
    "   Observe the “taming” of the variance, which abandons the green diagonal and follows the red logarithmic trajectory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b32e74f-3fae-4880-b96b-9649dc36f6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a994665e782f45fa8999f6c9577a461e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='N:', index=2, options=(512, 1024, 2048), value=2048), IntSlider(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CORRECTED AND OPTIMISED REFERENCE VERSION\n",
    "# Requirements: pandas, matplotlib, numpy, ipywidgets\n",
    "# Run in Colab or Jupyter with the appropriate kernel\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import time\n",
    "from scipy.stats import kstest\n",
    "\n",
    "# --- 1. OPTIMISED DATA GENERATION FUNCTIONS ---\n",
    "def generate_pi_data(n: int) -> np.ndarray:\n",
    "    \"\"\"Generate an array of all primes up to n using an optimised sieve.\"\"\"\n",
    "    if n < 2:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    size = (n - 1) // 2\n",
    "    sieve = np.ones(size, dtype=bool)\n",
    "    limit = int(np.sqrt(n)) // 2\n",
    "    for i in range(limit):\n",
    "        if sieve[i]:\n",
    "            p = 2 * i + 3\n",
    "            start = (p * p - 3) // 2\n",
    "            sieve[start::p] = False\n",
    "    indices = np.where(sieve)[0]\n",
    "    odd_primes = 2 * indices + 3\n",
    "    return np.concatenate((np.array([2], dtype=np.int64), odd_primes))\n",
    "\n",
    "def get_delta_pi_for_points(x_points, primes):\n",
    "    \"\"\"Compute Δπ(x) for an array of x values using a precomputed prime list.\"\"\"\n",
    "    x_int = np.floor(x_points).astype(int)\n",
    "    pi_x = np.searchsorted(primes, x_int, side='right')\n",
    "    pi_x_div_2 = np.searchsorted(primes, x_int // 2, side='right')\n",
    "    return pi_x - 2 * pi_x_div_2\n",
    "\n",
    "# --- 2. MATRIX FUNCTION (WITH NORMALISATION) ---\n",
    "def generate_cos_matrix_from_data(fx_values, x_values):\n",
    "    fx = fx_values.astype(np.float64)\n",
    "    x = x_values.astype(np.float64)\n",
    "    x[x <= 0] = 1e-12\n",
    "    logx = np.log(x)\n",
    "    C = np.cos(np.outer(fx, logx))\n",
    "    M = C + C.T\n",
    "    # Crucial normalisation step (previously omitted):\n",
    "    std_dev = M.std()\n",
    "    if std_dev > 0:\n",
    "        M = (M - M.mean()) / std_dev\n",
    "    return 0.5 * (M + M.T)\n",
    "\n",
    "# --- 3. ANALYSIS FUNCTIONS AND METRICS ---\n",
    "def local_normalize_spacings(lam, alpha=0.10, w=11):\n",
    "    lam = np.sort(lam)\n",
    "    N = lam.size\n",
    "    k0, k1 = int(alpha * N), int((1 - alpha) * N)\n",
    "    l = lam[k0:k1]\n",
    "    s = np.diff(l)\n",
    "    s = s[s > 0]\n",
    "    if len(s) < w:\n",
    "        return s / s.mean() if s.mean() > 0 else s\n",
    "    w = int(w)\n",
    "    if w % 2 == 0:\n",
    "        w += 1\n",
    "    pad = w // 2\n",
    "    s_pad = np.pad(s, (pad, pad), mode='reflect')\n",
    "    mu = np.convolve(s_pad, np.ones(w) / w, mode='valid')\n",
    "    return s / mu\n",
    "\n",
    "def r_mbb_bootstrap(s, B=1000, block_size=16, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(s)\n",
    "    if n < 2 * block_size:\n",
    "        return np.nan, (np.nan, np.nan)\n",
    "    num_blocks = int(np.ceil(n / block_size))\n",
    "    r_bootstrapped = []\n",
    "    for _ in range(B):\n",
    "        start_indices = rng.integers(0, n - block_size + 1, size=num_blocks)\n",
    "        s_resampled = np.concatenate(\n",
    "            [s[i:i + block_size] for i in start_indices]\n",
    "        )[:n]\n",
    "        if len(s_resampled) < 2:\n",
    "            continue\n",
    "        r_vals = np.minimum(\n",
    "            s_resampled[:-1], s_resampled[1:]\n",
    "        ) / np.maximum(\n",
    "            s_resampled[:-1], s_resampled[1:]\n",
    "        )\n",
    "        r_bootstrapped.append(np.mean(r_vals))\n",
    "    if not r_bootstrapped:\n",
    "        return np.nan, (np.nan, np.nan)\n",
    "    mean_r = np.mean(r_bootstrapped)\n",
    "    ci_95 = np.percentile(r_bootstrapped, [2.5, 97.5])\n",
    "    return mean_r, ci_95\n",
    "\n",
    "def number_variance(lam, alpha=0.10, L_grid=np.linspace(0.5, 15, 30)):\n",
    "    s_loc = local_normalize_spacings(lam, alpha=alpha)\n",
    "    if len(s_loc) == 0:\n",
    "        return L_grid, np.full_like(L_grid, np.nan)\n",
    "    x_unfolded = np.concatenate([[0], np.cumsum(s_loc)])\n",
    "    Sigma2 = []\n",
    "    for L in L_grid:\n",
    "        counts = [\n",
    "            np.searchsorted(x_unfolded, x_unfolded[i0] + L, side='right') - (i0 + 1)\n",
    "            for i0 in range(len(x_unfolded) - 1)\n",
    "        ]\n",
    "        Sigma2.append(np.var(counts) if counts else np.nan)\n",
    "    return L_grid, np.array(Sigma2)\n",
    "\n",
    "def r_stat(eigenvalues, alpha=0.10):\n",
    "    \"\"\"Compute the <r> statistic for eigenvalues.\"\"\"\n",
    "    lam = np.sort(eigenvalues)\n",
    "    k0, k1 = int(alpha * len(lam)), int((1 - alpha) * len(lam))\n",
    "    s = np.diff(lam[k0:k1])\n",
    "    s = s[s > 0]\n",
    "    if len(s) < 3:\n",
    "        return np.nan\n",
    "    r = np.minimum(s[1:], s[:-1]) / np.maximum(s[1:], s[:-1])\n",
    "    return r.mean()\n",
    "\n",
    "def participation_ratio(eigenvectors):\n",
    "    \"\"\"Compute the Participation Ratio for a matrix of eigenvectors.\"\"\"\n",
    "    return 1 / np.sum(eigenvectors**4, axis=0)\n",
    "\n",
    "# --- 4. MAIN INTERACTIVE FUNCTION ---\n",
    "def eigenvalue_lab(\n",
    "    N=2048,\n",
    "    log_X0=8,\n",
    "    scale_type='Logarithmic',\n",
    "    span=4.0,\n",
    "    jitter=1e-8,\n",
    "    alpha=0.05\n",
    "):\n",
    "\n",
    "    X0 = int(10**log_X0)\n",
    "\n",
    "    # --- 1. Matrix Construction ---\n",
    "    print(f\"Building M for N={N}, X0={X0:g} (scale: {scale_type})...\")\n",
    "    if scale_type == 'Logarithmic':\n",
    "        x_vals = np.exp(\n",
    "            np.linspace(np.log(X0) - span / 2,\n",
    "                        np.log(X0) + span / 2, N)\n",
    "        )\n",
    "        if jitter > 0:\n",
    "            rng = np.random.default_rng(0)\n",
    "            x_vals *= (1.0 + rng.uniform(-jitter, jitter, size=x_vals.shape))\n",
    "\n",
    "        # Ensure uniqueness of x values\n",
    "        x_vals = np.unique(np.floor(x_vals))\n",
    "        N = len(x_vals)\n",
    "\n",
    "    elif scale_type == 'Linear':\n",
    "        x_vals = np.arange(X0, X0 + N)\n",
    "    else:\n",
    "        print(\"Invalid scale type.\")\n",
    "        return\n",
    "\n",
    "    max_x_needed = int(np.ceil(x_vals.max()))\n",
    "    pi_x_full = generate_pi_data(max_x_needed)\n",
    "    fx_vals = get_delta_pi_for_points(x_vals, pi_x_full)\n",
    "    M = generate_cos_matrix_from_data(fx_vals, x_vals)\n",
    "\n",
    "    # --- 5. Eigenvalues and Eigenvectors ---\n",
    "    lam, v = np.linalg.eigh(M)\n",
    "\n",
    "    # --- 6. METRICS ---\n",
    "    r_mean = r_stat(lam, alpha=alpha)\n",
    "    pr_values = participation_ratio(v)\n",
    "    pr_n_mean = np.mean(pr_values / N)\n",
    "\n",
    "    print(\"\\n----------------------------------------------------------------\")\n",
    "    print(f\"  RESULTS: METRICS FOR X₀=10^{log_X0} AND N={N} ({scale_type})\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"  Eigenvalues -> mean <r>:\")\n",
    "    print(f\"    - Measured:        {r_mean:.4f}\")\n",
    "    print(\"    - Theoretical (GOE):     ~0.536\")\n",
    "    print(\"    - Theoretical (Poisson): ~0.386\\n\")\n",
    "    print(\"  Eigenvectors -> mean PR/N:\")\n",
    "    print(f\"    - Measured:        {pr_n_mean:.4f}\")\n",
    "    print(\"    - Theoretical (GOE):     ~0.333\")\n",
    "    print(\"    - Theoretical (Poisson): ~1/N (→ 0)\")\n",
    "    print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "    # --- 7. ANALYSIS AND PLOTS ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    k0, k1 = int(alpha * N), int((1 - alpha) * N)\n",
    "    bulk_lam = np.sort(lam)[k0:k1]\n",
    "    s = np.diff(bulk_lam)\n",
    "    s = s[s > 0]\n",
    "\n",
    "    if s.size > 1:\n",
    "        s_unfolded = s / s.mean()\n",
    "        axes[0].hist(\n",
    "            s_unfolded, bins=75, density=True,\n",
    "            alpha=0.7, label=f'Data (N={N})'\n",
    "        )\n",
    "\n",
    "    s_grid = np.linspace(0, 4, 200)\n",
    "    pdf_goe = (np.pi * s_grid / 2) * np.exp(-np.pi * s_grid**2 / 4)\n",
    "    axes[0].plot(s_grid, pdf_goe, 'r--', lw=2, label='GOE Theory (Wigner)')\n",
    "    pdf_poisson = np.exp(-s_grid)\n",
    "    axes[0].plot(s_grid, pdf_poisson, 'g:', lw=2, label='Poisson Theory')\n",
    "    axes[0].set_title('a) Spacing Distribution P(s)', fontsize=14)\n",
    "    axes[0].set_xlabel('s (Normalised Spacing)')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    axes[0].legend(loc='upper left')\n",
    "    axes[0].set_xlim(0, 4)\n",
    "\n",
    "    mean_r_boot, ci = r_mbb_bootstrap(s)\n",
    "    if not np.isnan(mean_r_boot):\n",
    "        ci_low, ci_high = ci\n",
    "        axes[1].errorbar(\n",
    "            [0], [mean_r_boot],\n",
    "            yerr=[[mean_r_boot - ci_low], [ci_high - ci_low]],\n",
    "            fmt='o', capsize=5,\n",
    "            label='<r> Measured (95% CI)'\n",
    "        )\n",
    "\n",
    "    axes[1].axhline(0.5359, ls='--', color='red', label='GOE Reference ≈ 0.536')\n",
    "    axes[1].axhline(0.3863, ls=':', color='green', label='Poisson Reference ≈ 0.386')\n",
    "    axes[1].set_title('b) Mean <r>', fontsize=14)\n",
    "    axes[1].set_ylabel('<r>')\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].legend(loc='center left')\n",
    "\n",
    "    L_grid, Sigma2 = number_variance(lam, alpha=alpha)\n",
    "    axes[2].plot(L_grid, Sigma2, 'o-', label='Data')\n",
    "    axes[2].plot(L_grid, L_grid, 'g:', lw=2, label='Poisson Theory (L)')\n",
    "    axes[2].plot(\n",
    "        L_grid,\n",
    "        (2 / (np.pi**2)) * np.log(L_grid) + 0.44,\n",
    "        'r--', lw=2, label='GOE Theory (log L)'\n",
    "    )\n",
    "    axes[2].set_title('c) Number Variance Σ²(L)', fontsize=14)\n",
    "    axes[2].set_xlabel('L')\n",
    "    axes[2].set_ylabel('Σ²(L)')\n",
    "    axes[2].legend(loc='upper left')\n",
    "\n",
    "    fig.tight_layout(pad=2.0)\n",
    "    plt.show()\n",
    "\n",
    "# --- INTERACTIVE WIDGET ---\n",
    "interact(\n",
    "    eigenvalue_lab,\n",
    "    N=widgets.Dropdown(\n",
    "        options=[512, 1024, 2048],\n",
    "        value=2048,\n",
    "        description='N:'\n",
    "    ),\n",
    "    log_X0=widgets.IntSlider(\n",
    "        min=3, max=8, step=1,\n",
    "        value=5,\n",
    "        description='X₀=10^',\n",
    "        continuous_update=False\n",
    "    ),\n",
    "    scale_type=widgets.ToggleButtons(\n",
    "        options=['Logarithmic', 'Linear'],\n",
    "        description='Scale:'\n",
    "    ),\n",
    "    span=widgets.FloatSlider(\n",
    "        min=1.0, max=4.0, step=0.1,\n",
    "        value=4.0,\n",
    "        description='Span:'\n",
    "    ),\n",
    "    jitter=widgets.FloatLogSlider(\n",
    "        min=-8, max=-3, step=0.1,\n",
    "        value=1e-8,\n",
    "        description='Jitter:'\n",
    "    ),\n",
    "    alpha=widgets.FloatSlider(\n",
    "        min=0.05, max=0.25, step=0.01,\n",
    "        value=0.05,\n",
    "        description='α (bulk):'\n",
    "    )\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2be83c-b0f7-4526-b16e-fb3903edab8a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Parameter Glossary: Focusing the Spectrometer\n",
    "\n",
    "To extract the GOE “music” from our matrix $ M $, it is not enough merely to construct it; it must be observed in the proper way.  \n",
    "The parameters `span`, `jitter`, and `alpha` act as the focus and sensitivity controls of our **“harmonic spectrometer”**.  \n",
    "Understanding the role of each is essential in order to hear the arithmetic cosmos with clarity.\n",
    "\n",
    "---\n",
    "\n",
    "### What is `span`? — *The Lens: Panorama versus Microscope*\n",
    "\n",
    "The `span` controls the **width of the observation window** on the logarithmic scale. It determines how many “valleys” and “plateaux”  \n",
    "of the function $ \\Delta\\_pi(x) $ are incorporated into the construction of the matrix. It is the most sensitive parameter and, in many  \n",
    "experiments, the one that decides whether we observe amorphous noise or a perfect symphony.\n",
    "\n",
    "> **The decisive experiment:**\n",
    ">\n",
    "> * With `span = 2.4`, the system produces metrics close to those of the GOE.  \n",
    "> * With `span = 4.0`, the harmony becomes complete: at $ X_0 = 10^5 $, the measured value is $ 0.536 $, identical to theory.\n",
    "\n",
    "This shows that the GOE signature can emerge at smaller scales than might be expected ($ X_0 = 10^5 $), provided that the **internal variation  \n",
    "captured** (`span`) is sufficient to represent the complexity of the signal $ \\Delta_\\pi(x) $. The larger the `span`, the more completely the  \n",
    "logarithmic mirror reflects the full structure of prime counting.\n",
    "\n",
    "**Summary:** `span` is the field-of-view control — the lens that allows one to see the full resonance of arithmetic.\n",
    "\n",
    "---\n",
    "\n",
    "### What is `jitter`? — *Symmetry Breaking and the Proof of Determinism*\n",
    "\n",
    "The `jitter` introduces a minute perturbation in the sampled $ x $ positions, breaking the rigid symmetries of the sampling grid.\n",
    "\n",
    "* It prevents numerical artefacts (aliasing) from mimicking spurious patterns of coherence.  \n",
    "* The experiment with `jitter = 1e−8` revealed something fundamental: even with external randomness virtually eliminated, the GOE structure  \n",
    "  **remains intact**.\n",
    "\n",
    "> **Experimental conclusion:**\n",
    "> `jitter` does not *create* harmonic chaos; it merely reveals it more sharply by removing “echoes” of the sampling ruler. This demonstrates  \n",
    "> that the correlation between eigenvalues is **deterministic**, not statistical. Quantum chaos emerges from arithmetic itself, without the need  \n",
    "> for external interference.\n",
    "\n",
    "**Summary:** `jitter` is the system’s minimal breath — useful for removing grid artefacts, but not essential to the intrinsic harmony.\n",
    "\n",
    "---\n",
    "\n",
    "### What is `bulk` (via `alpha`)? — *The Heart of the Spectrum*\n",
    "\n",
    "The parameter `alpha` defines the fraction discarded at the edges of the spectrum, isolating the `bulk`: the core region where universality  \n",
    "manifests itself without contamination from matrix edge effects. With $ \\alpha = 0.05 $, we remove 5% at each end, observing the **central\n",
    "90%** of the eigenvalues — the most stable and uncontaminated region.\n",
    "\n",
    "> Even with this large majority under analysis, the GOE metrics are preserved. The core alone already contains the full harmonic structure  \n",
    "> required for recognition of the universal class.\n",
    "\n",
    "In physical terms, it is as if the GOE symmetry field were already fully formed within a single “central chord”, independent of the edges  \n",
    "for its validation.\n",
    "\n",
    "**Summary:** `alpha` defines the heart of the spectrum — the interval in which number speaks the language of universality.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Synthesis\n",
    "\n",
    "With `span = 4`, `jitter = 1e−8`, and $ \\alpha = 0.05 $, we observe the **GOE emerging with absolute precision** already at  \n",
    "$ X_0 = 10^5 $. This means that harmonic chaos is **immediate**: the arithmetic universe does not require infinite vastness in order to behave  \n",
    "like the quantum cosmos — it already contains, within finite windows, the complete reflection of the Unity.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
