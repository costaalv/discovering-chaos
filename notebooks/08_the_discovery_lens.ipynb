{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc0da52e-3dc8-47f8-b30c-9a958ba78c4c",
   "metadata": {},
   "source": [
    "# 8 · The Appropriate Optics: Why the Logarithmic Scale Is Structural\n",
    "\n",
    "**Observational record associated with the book**  \n",
    "*Hidden Structure in the Apparent Chaos of Prime Numbers — Computational experiments through the Euler mirror*  \n",
    "© Alvaro Costa, 2025\n",
    "\n",
    "This notebook is part of a canonical sequence of computational records.  \n",
    "It introduces **no new hypotheses, conjectures, or interpretative models**.\n",
    "\n",
    "Its sole purpose is to **record** the behaviour of arithmetic structures under an explicit,  \n",
    "deterministic, and reproducible regime of observation.\n",
    "\n",
    "The complete conceptual discussion is presented in the book.  \n",
    "This notebook documents only the corresponding experiment.\n",
    "\n",
    "**Licence:** Creative Commons BY–NC–ND 4.0  \n",
    "Reading, execution, and citation are permitted.  \n",
    "Modification, derivative redistribution, or independent commercial use are not permitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5beb75-e4aa-42e2-9beb-4709fbc82bbc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. The Mystery of the Two Musics\n",
    "\n",
    "In the previous chapters, we celebrated the emergence of the GOE “music” from our operator $ M $. A closer examination, however, reveals a puzzle: depending  \n",
    "on how we observe the number line, the very same score sounds different.\n",
    "\n",
    "When a **linear sampling** is used, the spectrum of $ M $ approaches **Poisson** statistics. Under **logarithmic sampling**, by contrast, the **GOE** emerges  \n",
    "clearly. Why does the same methodology, applied to the same arithmetic region, produce two such distinct “musics”? Could this be an artefact?\n",
    "\n",
    "The answer is no. What we are witnessing is a fundamental phenomenon: the way we observe the system changes what the system reveals. The key lies in the natural  \n",
    "scale of the prime numbers themselves.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. The Two Lenses and the Natural Scale of the Primes\n",
    "\n",
    "The scale that naturally fits the primes is the **logarithmic** one, as Gauss already observed when noting that the density of primes around a number $ x $ is  \n",
    "approximately $ 1/\\ln(x) $. To perceive the global structure of the primes, we need a ruler that expands with them — and that ruler is the logarithmic scale.\n",
    "\n",
    "Sampling methods therefore act as **two lenses**: one calibrated to this natural scale, and another that ignores it.\n",
    "\n",
    "---\n",
    "\n",
    "### The “Panoramic” Lens (Logarithmic Sampling)\n",
    "\n",
    "This is the natural lens, tuned to the rhythm of the primes. By sampling points at logarithmic intervals, we observe the numerical universe with the appropriate  \n",
    "ruler — one that grows together with the space itself.\n",
    "\n",
    "* **What the lens sees:** In this panoramic view, the arithmetic function $ \\Delta_\\pi(x) $ reveals its harmonic fluctuations and structural noise.\n",
    "* **The consequence:** The resulting matrix $ M $ has high effective complexity, resembling a real symmetric random matrix, and its spectrum exhibits the  \n",
    "    characteristic level repulsion of the **GOE (Gaussian Orthogonal Ensemble)**.\n",
    "\n",
    "---\n",
    "\n",
    "### The “Microscope” Lens (Linear Sampling)\n",
    "\n",
    "This lens applies a rigid ruler, without adapting to the logarithmic scale. It is like observing a mountain range through a magnifying glass: everything appears  \n",
    "flat, because the lens captures only a tiny fragment of the landscape.\n",
    "\n",
    "* **What the lens sees:** Within such a narrow region, the global trend disappears and $ \\Delta_\\pi(x) $ appears stable and smooth. Local fluctuations become almost  \n",
    "    independent — a regime of **decorrelation**.\n",
    "* **The consequence:** The matrix ( M ) constructed through this lens has low variability, and its spectrum behaves like a system of independent events — a **Poisson**  \n",
    "    statistic.\n",
    "\n",
    "---\n",
    "\n",
    "### Comparative Table\n",
    "\n",
    "| Feature                  | Linear Sampling (Microscope)            | Logarithmic Sampling (Panoramic)       |\n",
    "| ------------------------ | --------------------------------------- | -------------------------------------- |\n",
    "| **Alignment**            | Ignores the natural scale of the primes | Aligned with the natural scale (Gauss) |\n",
    "| **View of the function** | Locally “flat” region                   | Global fluctuations and harmonic noise |\n",
    "| **Matrix complexity**    | Low, ordered, predictable               | High, complex, pseudo-random           |\n",
    "| **Spectral outcome**     | **Poisson**                             | **GOE (Gaussian Orthogonal Ensemble)** |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. The Scale Laboratory: Connection with the Code\n",
    "\n",
    "The code cell below demonstrates this effect directly.  \n",
    "One technical detail is essential to reveal the Poisson structure: the function `local_normalize_spacings`.\n",
    "\n",
    "Because the linear lens observes only a “nearly flat” region, the density of eigenvalues may vary slightly.  \n",
    "Local normalisation acts as a **fine-focus adjustment** — it rescales each spacing according to its immediate neighbourhood, restoring a faithful view of the Poisson  \n",
    "regime.\n",
    "\n",
    "This procedure does not create the pattern; it reveals it.  \n",
    "When `local_normalize_spacings` is applied, the Poisson distribution appears sharply — demonstrating that it is a **genuine property of the system at this scale**,  \n",
    "not a numerical artefact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c485b0ed-76a7-4707-ab67-57b0d5c26623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3612ad7f58c94f24ae0667fa18ceb562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='N:', index=2, options=(512, 1024, 2048), value=2048), IntSlider(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Requirements: pandas, matplotlib, numpy, ipywidgets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import time\n",
    "\n",
    "# --- Data Generation and Matrix Functions ---\n",
    "def generate_pi_data(n: int) -> np.ndarray:\n",
    "    \"\"\"Generates an array containing all primes up to n using an optimised sieve.\"\"\"\n",
    "    if n < 2: return np.array([], dtype=np.int64)\n",
    "    size = (n - 1) // 2; sieve = np.ones(size, dtype=bool)\n",
    "    limit = int(np.sqrt(n)) // 2\n",
    "    for i in range(limit):\n",
    "        if sieve[i]:\n",
    "            p = 2 * i + 3; start = (p*p - 3) // 2\n",
    "            sieve[start::p] = False\n",
    "    indices = np.where(sieve)[0]; odd_primes = 2 * indices + 3\n",
    "    return np.concatenate((np.array([2], dtype=np.int64), odd_primes))\n",
    "\n",
    "def get_delta_pi_for_points(x_points, primes):\n",
    "    \"\"\"Computes Δπ(x) for an array of x-points using a precomputed list of primes.\"\"\"\n",
    "    x_int = np.floor(x_points).astype(int)\n",
    "    pi_x = np.searchsorted(primes, x_int, side='right')\n",
    "    pi_x_div_2 = np.searchsorted(primes, x_int // 2, side='right')\n",
    "    return pi_x - 2 * pi_x_div_2\n",
    "    \n",
    "def generate_cos_matrix(fx_values, x_values):\n",
    "    \"\"\"Generates the matrix M from the vectors F(x) and x.\"\"\"\n",
    "    fx = fx_values.astype(np.float64); x = x_values.astype(np.float64)\n",
    "    x[x <= 0] = 1e-12; logx = np.log(x)\n",
    "    C = np.cos(np.outer(fx, logx)); M = C + C.T\n",
    "    std_dev = M.std()\n",
    "    if std_dev > 0:\n",
    "        M -= M.mean()\n",
    "        M /= std_dev\n",
    "    return 0.5 * (M + M.T)\n",
    "\n",
    "# Fixed bulk: central 90% (alpha = 0.10)\n",
    "# Fixed local window for unfolding (not optimised): w = 21\n",
    "def local_normalize_spacings(lam, alpha=0.10, w=21):\n",
    "    \"\"\"\n",
    "    Normalises spacings by their local mean (unfolding).\n",
    "    This is the key step to correctly visualise Poisson statistics.\n",
    "    \"\"\"\n",
    "    N = lam.size\n",
    "    # Extract the spectral bulk to avoid edge effects\n",
    "    k0, k1 = int(alpha * N), int((1 - alpha) * N)\n",
    "    lam_bulk = np.sort(lam)[k0:k1]\n",
    "    \n",
    "    s = np.diff(lam_bulk)\n",
    "    s = s[s > 0]\n",
    "    \n",
    "    if len(s) < w: \n",
    "        return s / s.mean() if s.mean() > 0 else s\n",
    "\n",
    "    # Use a moving average to estimate the local density of states\n",
    "    w = int(w)\n",
    "    if w % 2 == 0: w += 1  # Window length must be odd\n",
    "    pad = w // 2\n",
    "    s_padded = np.pad(s, (pad, pad), mode='reflect')\n",
    "    local_mean = np.convolve(s_padded, np.ones(w)/w, mode='valid')\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    local_mean[local_mean == 0] = 1.0\n",
    "    \n",
    "    return s / local_mean\n",
    "\n",
    "# --- Main Interactive Function ---\n",
    "def scale_comparison_lab(N=2048, log_X0=8, span=2.4):\n",
    "    \n",
    "    X0 = int(10**log_X0)\n",
    "    \n",
    "    # --- Data Preparation ---\n",
    "    max_x_log = int(np.ceil(X0 * np.exp(span/2)))\n",
    "    max_x_linear = X0 + N\n",
    "    max_x_needed = max(max_x_log, max_x_linear)\n",
    "    pi_x_full = generate_pi_data(max_x_needed)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True) \n",
    "    \n",
    "    # --- Left Plot: Linear Sampling (Poisson) ---\n",
    "    print(\"\\n--- Processing Linear Scale ---\")\n",
    "    x_linear = np.arange(X0, X0 + N)\n",
    "    fx_linear = get_delta_pi_for_points(x_linear, pi_x_full)\n",
    "    \n",
    "    M_linear = generate_cos_matrix(fx_linear, x_linear)\n",
    "    lam_linear, _ = np.linalg.eigh(M_linear)\n",
    "    # USE LOCAL NORMALISATION TO REVEAL POISSON\n",
    "    s_unfolded_linear = local_normalize_spacings(lam_linear)\n",
    "\n",
    "    # --- Right Plot: Logarithmic Sampling (GOE) ---\n",
    "    print(\"\\n--- Processing Logarithmic Scale ---\")\n",
    "    x_log = np.exp(np.linspace(np.log(X0) - span/2, np.log(X0) + span/2, N))\n",
    "    fx_log = get_delta_pi_for_points(x_log, pi_x_full)\n",
    "\n",
    "    M_log = generate_cos_matrix(fx_log, x_log)\n",
    "    lam_log, _ = np.linalg.eigh(M_log)\n",
    "    # For GOE, global mean normalisation is sufficient\n",
    "    s_log = np.diff(np.sort(lam_log)); s_log = s_log[s_log > 0]\n",
    "    s_unfolded_log = s_log / s_log.mean()\n",
    "\n",
    "    # --- Comparative Plots ---\n",
    "    s_grid = np.linspace(0, 4, 200)\n",
    "    pdf_goe = (np.pi * s_grid / 2) * np.exp(-np.pi * s_grid**2 / 4)\n",
    "    pdf_poisson = np.exp(-s_grid)\n",
    "    \n",
    "    # Left plot\n",
    "    ax = axes[0]\n",
    "    ax.hist(s_unfolded_linear, bins='auto', density=True, alpha=0.75, label='Data (Linear)')\n",
    "    ax.plot(s_grid, pdf_goe, 'r--', lw=2, label='GOE Theory')\n",
    "    ax.plot(s_grid, pdf_poisson, 'g:', lw=3, label='Poisson Theory')\n",
    "    ax.set_title('a) Linear Scale → Uncorrelated Regime', fontsize=14)\n",
    "    ax.set_xlabel('s (Locally Normalised Spacing)'); ax.set_ylabel('Density')\n",
    "    ax.set_xlim(0, 4); ax.legend(loc='upper right')\n",
    "    \n",
    "    # Right plot\n",
    "    ax = axes[1]\n",
    "    ax.hist(s_unfolded_log, bins='auto', density=True, alpha=0.75, label='Data (Logarithmic)')\n",
    "    ax.plot(s_grid, pdf_goe, 'r--', lw=2, label='GOE Theory')\n",
    "    ax.plot(s_grid, pdf_poisson, 'g:', lw=3, label='Poisson Theory')\n",
    "    ax.set_title('b) Logarithmic Scale → Correlated Regime', fontsize=14)\n",
    "    ax.set_xlabel('s (Globally Normalised Spacing)'); ax.legend(loc='upper right')\n",
    "    ax.set_xlim(0, 4)\n",
    "    \n",
    "    fig.suptitle(\n",
    "        f\"Visual Comparison of the Effect of Scale at X₀ = {X0:g}\",\n",
    "        fontsize=18, weight='bold'\n",
    "    )\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "# --- Interactive Widget ---\n",
    "interact(\n",
    "    scale_comparison_lab, \n",
    "    N=widgets.Dropdown(options=[512, 1024, 2048], value=2048, description='N:'),\n",
    "    log_X0=widgets.IntSlider(\n",
    "        min=5, max=8, step=1, value=8,\n",
    "        description='X₀=10^', continuous_update=False\n",
    "    ),\n",
    "    span=widgets.FloatSlider(\n",
    "        min=1.0, max=4.0, step=0.1,\n",
    "        value=2.4, description='Span (Log):'\n",
    "    )\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e75f5f-172e-4a28-96e7-859fbc85c399",
   "metadata": {},
   "source": [
    "> With experimental proof in hand that the two lenses produce different kinds of music, we are ready to go deeper. In the next chapter, we will examine the *optics*  \n",
    "> of our logarithmic lens, delving into the mathematics that explains why it does not merely work, but why it is the **only** lens that could work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf4bef7-3472-4ea9-8804-c326f9203b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
