{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc0da52e-3dc8-47f8-b30c-9a958ba78c4c",
   "metadata": {},
   "source": [
    "# 8 · The Appropriate Optics: Why the Logarithmic Scale Is Structural\n",
    "\n",
    "**Observational record associated with the book**  \n",
    "*Discovering Chaos in Prime Numbers — Computational Investigations through the Euler Mirror*  \n",
    "© Alvaro Costa, 2025\n",
    "\n",
    "This notebook is part of a canonical sequence of computational records.  \n",
    "It introduces **no new hypotheses, conjectures, or interpretative models**.\n",
    "\n",
    "Its sole purpose is to **record** the behaviour of arithmetic structures under an explicit,  \n",
    "deterministic, and reproducible regime of observation.\n",
    "\n",
    "The complete conceptual discussion is presented in the book.  \n",
    "This notebook documents only the corresponding experiment.\n",
    "\n",
    "**Licence:** Creative Commons BY–NC–ND 4.0  \n",
    "Reading, execution, and citation are permitted.  \n",
    "Modification, derivative redistribution, or independent commercial use are not permitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5beb75-e4aa-42e2-9beb-4709fbc82bbc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Distinct statistical regimes under different observation metrics\n",
    "\n",
    "In the previous chapters, the emergence of statistics compatible with the GOE was observed for the operator $M$. A further analysis, however, reveals a crucial point: **the observed statistical regime depends on the sampling metric adopted along the number line**.\n",
    "\n",
    "When the points $x_i$ are sampled **linearly**, the spectrum of $M$ exhibits statistics compatible with a **Poisson** regime. When sampling is performed **logarithmically**, while keeping both the construction of the operator and the arithmetic region fixed, a **clearly correlated spectral regime** emerges, compatible with **GOE** statistics.\n",
    "\n",
    "This contrast is not a numerical artefact. It reflects the explicit dependence between the constructed operator and the observation metric employed.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Observation metric and the natural scale of the primes\n",
    "\n",
    "The asymptotic density of prime numbers is governed by the relation\n",
    "$$\n",
    "\\pi(x) \\sim \\frac{x}{\\ln x},\n",
    "$$\n",
    "which indicates that the natural scale associated with the distribution of primes is **logarithmic**, rather than linear.\n",
    "\n",
    "Consequently, the choice of sampling metric acts as a structural filter:\n",
    "\n",
    "* metrics compatible with the logarithmic scale preserve the relevant variations of the arithmetic signal;\n",
    "* incompatible metrics tend to suppress long-range correlations.\n",
    "\n",
    "Thus, different sampling strategies correspond to different observation regimes of the *same* operator.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Logarithmic sampling and the correlated regime\n",
    "\n",
    "When the points $x_i$ are distributed uniformly in $\\ln x$, the sampling remains coherent with the multiplicative structure implicit in the operator $M$.\n",
    "\n",
    "* **Effect on $\\Delta_\\pi(x)$:**\n",
    "  The fluctuations of the signal are sampled in a balanced manner across scales, preserving their structural variability.\n",
    "\n",
    "* **Spectral consequence:**\n",
    "  The resulting matrix $M$ exhibits high internal complexity, and its spectrum displays level repulsion characteristic of correlated statistics, compatible with the **GOE (Gaussian Orthogonal Ensemble)** class.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Linear sampling and the uncorrelated regime\n",
    "\n",
    "When the points $x_i$ are distributed uniformly in $x$, the sampling ignores the logarithmic scale underlying the distribution of the primes.\n",
    "\n",
    "* **Effect on $\\Delta_\\pi(x)$:**\n",
    "  Within restricted linear windows, the signal varies slowly and exhibits approximately independent fluctuations.\n",
    "\n",
    "* **Spectral consequence:**\n",
    "  The matrix $M$ constructed in this regime has lower effective variability, and the resulting spectrum is compatible with statistics of independent events, that is, a **Poisson** regime.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Comparison between observation regimes\n",
    "\n",
    "| Characteristic                 | Linear sampling | Logarithmic sampling   |\n",
    "| ------------------------------ | --------------- | ---------------------- |\n",
    "| Sampling metric                | Linear in $x$   | Uniform in $\\ln x$     |\n",
    "| Compatibility with $\\pi(x)$    | Low             | High                   |\n",
    "| Variability of $\\Delta_\\pi(x)$ | Locally reduced | Structurally preserved |\n",
    "| Complexity of operator $M$     | Low             | High                   |\n",
    "| Spectral statistics            | Poisson         | GOE                    |\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Local normalisation and verification of the Poisson regime\n",
    "\n",
    "In the linear regime, small residual variations in the spectral density may obscure the identification of Poisson behaviour.\n",
    "\n",
    "The function `local_normalize_spacings` applies a local normalisation of the spectral spacings, compensating for smooth variations in the mean density.\n",
    "\n",
    "This procedure:\n",
    "\n",
    "* **does not introduce correlation**;\n",
    "* **does not modify the operator**;\n",
    "* merely removes scale effects that could mask the underlying statistical regime.\n",
    "\n",
    "After this normalisation, the Poisson distribution emerges clearly, confirming that it is an **observational property of the system under this metric**, rather than a computational artefact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c485b0ed-76a7-4707-ab67-57b0d5c26623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781b873201144398acf1d0bb71ee88d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='N:', index=2, options=(512, 1024, 2048), value=2048), IntSlider(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Requirements: pandas, matplotlib, numpy, ipywidgets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import time\n",
    "\n",
    "# --- Data Generation and Matrix Functions ---\n",
    "def generate_pi_data(n: int) -> np.ndarray:\n",
    "    \"\"\"Generates an array containing all primes up to n using an optimised sieve.\"\"\"\n",
    "    if n < 2: return np.array([], dtype=np.int64)\n",
    "    size = (n - 1) // 2; sieve = np.ones(size, dtype=bool)\n",
    "    limit = int(np.sqrt(n)) // 2\n",
    "    for i in range(limit):\n",
    "        if sieve[i]:\n",
    "            p = 2 * i + 3; start = (p*p - 3) // 2\n",
    "            sieve[start::p] = False\n",
    "    indices = np.where(sieve)[0]; odd_primes = 2 * indices + 3\n",
    "    return np.concatenate((np.array([2], dtype=np.int64), odd_primes))\n",
    "\n",
    "def get_delta_pi_for_points(x_points, primes):\n",
    "    \"\"\"Computes Δπ(x) for an array of x-points using a precomputed list of primes.\"\"\"\n",
    "    x_int = np.floor(x_points).astype(int)\n",
    "    pi_x = np.searchsorted(primes, x_int, side='right')\n",
    "    pi_x_div_2 = np.searchsorted(primes, x_int // 2, side='right')\n",
    "    return pi_x - 2 * pi_x_div_2\n",
    "    \n",
    "def generate_cos_matrix(fx_values, x_values):\n",
    "    \"\"\"Generates the matrix M from the vectors F(x) and x.\"\"\"\n",
    "    fx = fx_values.astype(np.float64); x = x_values.astype(np.float64)\n",
    "    x[x <= 0] = 1e-12; logx = np.log(x)\n",
    "    C = np.cos(np.outer(fx, logx)); M = C + C.T\n",
    "    std_dev = M.std()\n",
    "    if std_dev > 0:\n",
    "        M -= M.mean()\n",
    "        M /= std_dev\n",
    "    return 0.5 * (M + M.T)\n",
    "\n",
    "# Fixed bulk: central 90% (alpha = 0.10)\n",
    "# Fixed local window for unfolding (not optimised): w = 21\n",
    "def local_normalize_spacings(lam, alpha=0.10, w=21):\n",
    "    \"\"\"\n",
    "    Normalises spacings by their local mean (unfolding).\n",
    "    This is the key step to correctly visualise Poisson statistics.\n",
    "    \"\"\"\n",
    "    N = lam.size\n",
    "    # Extract the spectral bulk to avoid edge effects\n",
    "    k0, k1 = int(alpha * N), int((1 - alpha) * N)\n",
    "    lam_bulk = np.sort(lam)[k0:k1]\n",
    "    \n",
    "    s = np.diff(lam_bulk)\n",
    "    s = s[s > 0]\n",
    "    \n",
    "    if len(s) < w: \n",
    "        return s / s.mean() if s.mean() > 0 else s\n",
    "\n",
    "    # Use a moving average to estimate the local density of states\n",
    "    w = int(w)\n",
    "    if w % 2 == 0: w += 1  # Window length must be odd\n",
    "    pad = w // 2\n",
    "    s_padded = np.pad(s, (pad, pad), mode='reflect')\n",
    "    local_mean = np.convolve(s_padded, np.ones(w)/w, mode='valid')\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    local_mean[local_mean == 0] = 1.0\n",
    "    \n",
    "    return s / local_mean\n",
    "\n",
    "# --- Main Interactive Function ---\n",
    "def scale_comparison_lab(N=2048, log_X0=8, span=2.4):\n",
    "    \n",
    "    X0 = int(10**log_X0)\n",
    "    \n",
    "    # --- Data Preparation ---\n",
    "    max_x_log = int(np.ceil(X0 * np.exp(span/2)))\n",
    "    max_x_linear = X0 + N\n",
    "    max_x_needed = max(max_x_log, max_x_linear)\n",
    "    pi_x_full = generate_pi_data(max_x_needed)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True) \n",
    "    \n",
    "    # --- Left Plot: Linear Sampling (Poisson) ---\n",
    "    print(\"\\n--- Processing Linear Scale ---\")\n",
    "    x_linear = np.arange(X0, X0 + N)\n",
    "    fx_linear = get_delta_pi_for_points(x_linear, pi_x_full)\n",
    "    \n",
    "    M_linear = generate_cos_matrix(fx_linear, x_linear)\n",
    "    lam_linear, _ = np.linalg.eigh(M_linear)\n",
    "    # USE LOCAL NORMALISATION TO REVEAL POISSON\n",
    "    s_unfolded_linear = local_normalize_spacings(lam_linear)\n",
    "\n",
    "    # --- Right Plot: Logarithmic Sampling (GOE) ---\n",
    "    print(\"\\n--- Processing Logarithmic Scale ---\")\n",
    "    x_log = np.exp(np.linspace(np.log(X0) - span/2, np.log(X0) + span/2, N))\n",
    "    fx_log = get_delta_pi_for_points(x_log, pi_x_full)\n",
    "\n",
    "    M_log = generate_cos_matrix(fx_log, x_log)\n",
    "    lam_log, _ = np.linalg.eigh(M_log)\n",
    "    # For GOE, global mean normalisation is sufficient\n",
    "    s_log = np.diff(np.sort(lam_log)); s_log = s_log[s_log > 0]\n",
    "    s_unfolded_log = s_log / s_log.mean()\n",
    "\n",
    "    # --- Comparative Plots ---\n",
    "    s_grid = np.linspace(0, 4, 200)\n",
    "    pdf_goe = (np.pi * s_grid / 2) * np.exp(-np.pi * s_grid**2 / 4)\n",
    "    pdf_poisson = np.exp(-s_grid)\n",
    "    \n",
    "    # Left plot\n",
    "    ax = axes[0]\n",
    "    ax.hist(s_unfolded_linear, bins='auto', density=True, alpha=0.75, label='Data (Linear)')\n",
    "    ax.plot(s_grid, pdf_goe, 'r--', lw=2, label='GOE Theory')\n",
    "    ax.plot(s_grid, pdf_poisson, 'g:', lw=3, label='Poisson Theory')\n",
    "    ax.set_title('a) Linear Scale → Uncorrelated Regime', fontsize=14)\n",
    "    ax.set_xlabel('s (Locally Normalised Spacing)'); ax.set_ylabel('Density')\n",
    "    ax.set_xlim(0, 4); ax.legend(loc='upper right')\n",
    "    \n",
    "    # Right plot\n",
    "    ax = axes[1]\n",
    "    ax.hist(s_unfolded_log, bins='auto', density=True, alpha=0.75, label='Data (Logarithmic)')\n",
    "    ax.plot(s_grid, pdf_goe, 'r--', lw=2, label='GOE Theory')\n",
    "    ax.plot(s_grid, pdf_poisson, 'g:', lw=3, label='Poisson Theory')\n",
    "    ax.set_title('b) Logarithmic Scale → Correlated Regime', fontsize=14)\n",
    "    ax.set_xlabel('s (Globally Normalised Spacing)'); ax.legend(loc='upper right')\n",
    "    ax.set_xlim(0, 4)\n",
    "    \n",
    "    fig.suptitle(\n",
    "        f\"Visual Comparison of the Effect of Scale at X₀ = {X0:g}\",\n",
    "        fontsize=18, weight='bold'\n",
    "    )\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "# --- Interactive Widget ---\n",
    "interact(\n",
    "    scale_comparison_lab, \n",
    "    N=widgets.Dropdown(options=[512, 1024, 2048], value=2048, description='N:'),\n",
    "    log_X0=widgets.IntSlider(\n",
    "        min=5, max=8, step=1, value=8,\n",
    "        description='X₀=10^', continuous_update=False\n",
    "    ),\n",
    "    span=widgets.FloatSlider(\n",
    "        min=1.0, max=4.0, step=0.1,\n",
    "        value=2.4, description='Span (Log):'\n",
    "    )\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e75f5f-172e-4a28-96e7-859fbc85c399",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Final observation\n",
    "\n",
    "The contrast between Poisson and GOE statistics does not indicate the presence of two distinct systems. Rather, it reflects the dependence of spectral statistics on the **compatibility between the operator and the observation metric**.\n",
    "\n",
    "In the next notebook, the mathematical structure that makes logarithmic sampling not merely convenient, but necessary for the observation of long-range spectral correlations in this operator, will be analysed in greater detail.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
