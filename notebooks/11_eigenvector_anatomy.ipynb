{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3bbd781-f876-4bb0-8016-403cd5e80536",
   "metadata": {},
   "source": [
    "# 11 · The Anatomy of Chaos — Eigenvector Analysis\n",
    "\n",
    "**Observational record associated with the book**  \n",
    "*Discovering Chaos in Prime Numbers — Computational Investigations through the Euler Mirror*  \n",
    "© Alvaro Costa, 2025\n",
    "\n",
    "This notebook is part of a canonical sequence of computational records.  \n",
    "It introduces **no new hypotheses, conjectures, or interpretative models**.\n",
    "\n",
    "Its purpose is exclusively to **record** the behaviour of arithmetic structures under an explicit,  \n",
    "deterministic, and reproducible observational regime.\n",
    "\n",
    "The complete conceptual discussion is presented in the book.  \n",
    "This notebook documents only the corresponding experiment.\n",
    "\n",
    "**Licence:** Creative Commons BY–NC–ND 4.0  \n",
    "Reading, execution, and citation are permitted.  \n",
    "Modification, adapted redistribution, or independent commercial use are not permitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deaad8d-f4c8-42c6-af92-1e27b712edf5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Beyond the Eigenvalues\n",
    "\n",
    "In the previous chapters, the analysis focused on the **eigenvalues** $ \\lambda_i $ of the operator $ M $.  \n",
    "They allowed us to characterise **where** spectral excitations are located and, through spacing statistics, to distinguish between  \n",
    "uncorrelated regimes (Poisson) and correlated regimes (GOE).\n",
    "\n",
    "In this notebook, the focus shifts to the **eigenvectors** $ v_i $.\n",
    "\n",
    "While the eigenvalues describe the global spectral structure, the eigenvectors reveal **how this structure manifests internally**.  \n",
    "They encode the “vibrational” patterns of the operator and allow us to assess whether the observed regime is merely statistically  \n",
    "compatible or structurally **ergodic**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Tool I — Participation Ratio ($PR$)\n",
    "\n",
    "The *Participation Ratio* ($PR$) quantifies the degree of **delocalisation** of an eigenvector.\n",
    "\n",
    "For a normalised eigenvector $ v = (v_1,\\dots,v_N) $, it is defined as:\n",
    "\n",
    "$\n",
    "\\mathrm{PR} = \\frac{1}{\\sum_{i=1}^{N} |v_i|^4}.\n",
    "$\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "* **Localised eigenvector**: concentrated on a few components $\\to \\text{small}\\, \\mathrm{PR}$ (of order unity).\n",
    "* **Delocalised eigenvector**: spread across the full space $\\to \\mathrm{PR}$ proportional to $ N $.\n",
    "\n",
    "In Random Matrix Theory, eigenvectors in the **GOE** class are ergodic.  \n",
    "In this case, the normalised ratio\n",
    "\n",
    "$\n",
    "\\frac{\\mathrm{PR}}{N}\n",
    "$\n",
    "\n",
    "concentrates around the universal value:\n",
    "\n",
    "$\n",
    "\\frac{1}{3}.\n",
    "$\n",
    "\n",
    "This value constitutes a **structural signature** of quantum chaos, independent of the detailed form of the operator.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Tool II — Statistics of the Components\n",
    "\n",
    "A second, independent prediction of Random Matrix Theory concerns the **individual components** of the eigenvectors.\n",
    "\n",
    "For matrices in the GOE class, the components of a typical *bulk* eigenvector behave as random variables drawn from a  \n",
    "**real Gaussian distribution**, with zero mean.\n",
    "\n",
    "In this notebook, this prediction is tested as follows:\n",
    "\n",
    "1. An eigenvector from the centre of the spectrum is selected.\n",
    "2. A histogram of its components is constructed.\n",
    "3. The histogram is compared with a theoretical Gaussian curve.\n",
    "4. The **Kolmogorov–Smirnov (KS) test** is applied to quantify compatibility.\n",
    "\n",
    "A high *p-value* indicates that there is no statistical evidence to reject the Gaussian hypothesis.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. The Eigenvector Laboratory\n",
    "\n",
    "The following code cells implement these two analyses in a comparative manner.\n",
    "\n",
    "Four plots are produced:\n",
    "\n",
    "* **Linear scale**:\n",
    "\n",
    "  * histogram of the components of an eigenvector;\n",
    "  * distribution of the values of $ \\mathrm{PR}/N $.\n",
    "\n",
    "* **Logarithmic scale**:\n",
    "\n",
    "  * histogram of the components of an eigenvector;\n",
    "  * distribution of the values of $ \\mathrm{PR}/N $.\n",
    "\n",
    "The objective is to verify whether the distinction observed in the eigenvalues (Poisson versus GOE) also manifests itself in the  \n",
    "**internal geometry** of the eigenvectors.\n",
    "\n",
    "The conceptual interpretation of these results is presented in the text of Chapter 11.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e61509-d502-4087-993d-1ea82f1cc746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7490034c41454905a6ef0c8bff7b42a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='N:', index=1, options=(512, 1024, 2048), value=1024), IntSlider(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Requirements: pandas, matplotlib, numpy, ipywidgets, scipy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import time\n",
    "from scipy.stats import kstest, norm\n",
    "\n",
    "# --- Data and Matrix Generation Functions (from the previous chapter) ---\n",
    "def generate_pi_data(n: int) -> np.ndarray:\n",
    "    \"\"\"Generates an array with all primes up to n using an optimised sieve.\"\"\"\n",
    "    if n < 2:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    size = (n - 1) // 2\n",
    "    sieve = np.ones(size, dtype=bool)\n",
    "    limit = int(np.sqrt(n)) // 2\n",
    "    for i in range(limit):\n",
    "        if sieve[i]:\n",
    "            p = 2 * i + 3\n",
    "            start = (p*p - 3) // 2\n",
    "            sieve[start::p] = False\n",
    "    indices = np.where(sieve)[0]\n",
    "    odd_primes = 2 * indices + 3\n",
    "    return np.concatenate((np.array([2], dtype=np.int64), odd_primes))\n",
    "\n",
    "\n",
    "def get_delta_pi_for_points(x_points, primes):\n",
    "    \"\"\"Computes Δπ(x) for an array of x values using a precomputed prime list.\"\"\"\n",
    "    x_int = np.floor(x_points).astype(int)\n",
    "    pi_x = np.searchsorted(primes, x_int, side='right')\n",
    "    pi_x_div_2 = np.searchsorted(primes, x_int // 2, side='right')\n",
    "    return pi_x - 2 * pi_x_div_2\n",
    "\n",
    "\n",
    "def generate_cos_matrix(fx_values, x_values):\n",
    "    \"\"\"Generates the matrix M from the vectors F(x) and x.\"\"\"\n",
    "    fx = fx_values.astype(np.float64)\n",
    "    x = x_values.astype(np.float64)\n",
    "    x[x <= 0] = 1e-12\n",
    "    logx = np.log(x)\n",
    "    C = np.cos(np.outer(fx, logx))\n",
    "    M = C + C.T\n",
    "    std_dev = M.std()\n",
    "    if std_dev > 0:\n",
    "        M -= M.mean()\n",
    "        M /= std_dev\n",
    "    return 0.5 * (M + M.T)\n",
    "\n",
    "\n",
    "# Eigenvector analysis function\n",
    "def calculate_participation_ratio(eigenvectors):\n",
    "    \"\"\"Computes the Participation Ratio for a matrix of eigenvectors.\"\"\"\n",
    "    # Eigenvectors returned by eigh are normalised (sum of squares equals 1)\n",
    "    # Formula: PR = 1 / sum(|v_i|^4)\n",
    "    return 1 / np.sum(eigenvectors**4, axis=0)\n",
    "\n",
    "\n",
    "# --- Main Interactive Function ---\n",
    "def eigenvector_analysis_lab(N=2048, log_X0=7):\n",
    "    \n",
    "    X0 = int(10**log_X0)\n",
    "    span = 2.4  # Fixed span for the logarithmic scale\n",
    "    \n",
    "    # --- Data preparation ---\n",
    "    max_x_log = int(np.ceil(X0 * np.exp(span/2)))\n",
    "    max_x_linear = X0 + N\n",
    "    max_x_needed = max(max_x_log, max_x_linear)\n",
    "    pi_x_full = generate_pi_data(max_x_needed)\n",
    "\n",
    "    # --- Linear scale analysis ---\n",
    "    print(\"\\n--- Processing Linear Scale ---\")\n",
    "    x_linear = np.arange(X0, X0 + N)\n",
    "    fx_linear = get_delta_pi_for_points(x_linear, pi_x_full)\n",
    "\n",
    "    # Jitter to ensure numerical stability\n",
    "    jitter = 1e-9 * (fx_linear.std() if fx_linear.std() > 0 else 1)\n",
    "    fx_linear_jittered = fx_linear.astype(np.float64) + np.random.uniform(\n",
    "        -jitter, jitter, size=fx_linear.shape\n",
    "    )\n",
    "\n",
    "    M_linear = generate_cos_matrix(fx_linear_jittered, x_linear)\n",
    "    lam_linear, v_linear = np.linalg.eigh(M_linear)\n",
    "    \n",
    "    # Eigenvector analysis\n",
    "    vec_linear = v_linear[:, N // 2]  # Eigenvector from the spectral centre\n",
    "    pr_linear = calculate_participation_ratio(v_linear)\n",
    "    ks_linear = kstest(vec_linear * np.sqrt(N), 'norm')  # Components scaled by sqrt(N)\n",
    "\n",
    "    # --- Logarithmic scale analysis ---\n",
    "    print(\"\\n--- Processing Logarithmic Scale ---\")\n",
    "    x_log = np.exp(np.linspace(np.log(X0) - span/2, np.log(X0) + span/2, N))\n",
    "    fx_log = get_delta_pi_for_points(x_log, pi_x_full)\n",
    "\n",
    "    M_log = generate_cos_matrix(fx_log, x_log)\n",
    "    lam_log, v_log = np.linalg.eigh(M_log)\n",
    "\n",
    "    # Eigenvector analysis\n",
    "    vec_log = v_log[:, N // 2]  # Eigenvector from the spectral centre\n",
    "    pr_log = calculate_participation_ratio(v_log)\n",
    "    ks_log = kstest(vec_log * np.sqrt(N), 'norm')\n",
    "\n",
    "    # --- Comparative plots (2x2 layout) ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle(\n",
    "        f\"Eigenvector Analysis for N={N}, X₀≈{X0:g}\",\n",
    "        fontsize=18,\n",
    "        weight='bold'\n",
    "    )\n",
    "\n",
    "    # --- Top row: Linear scale (Poisson) ---\n",
    "    # a) Eigenvector components\n",
    "    ax = axes[0, 0]\n",
    "    ax.hist(vec_linear * np.sqrt(N), bins=50, density=True, alpha=0.7, label='Components')\n",
    "    ax.set_title('a) Components of $v_i$ (Linear)', fontsize=14)\n",
    "    ax.set_xlabel(r'Components $v_i \\sqrt{N}$')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.text(\n",
    "        0.05, 0.95,\n",
    "        f'KS p-value: {ks_linear.pvalue:.2f}',\n",
    "        transform=ax.transAxes,\n",
    "        ha='left', va='top',\n",
    "        color='red'\n",
    "    )\n",
    "\n",
    "    # b) Participation Ratio\n",
    "    ax = axes[0, 1]\n",
    "    ax.hist(pr_linear / N, bins=50, density=True, alpha=0.7, label='PR/N')\n",
    "    mean_pr_linear = np.mean(pr_linear / N)\n",
    "    ax.axvline(mean_pr_linear, color='red', ls='--', label=f'Mean = {mean_pr_linear:.3f}')\n",
    "    ax.set_title('b) Participation Ratio (Linear)', fontsize=14)\n",
    "    ax.set_xlabel('PR / N')\n",
    "    ax.legend()\n",
    "\n",
    "    # --- Bottom row: Logarithmic scale (GOE) ---\n",
    "    # c) Eigenvector components\n",
    "    ax = axes[1, 0]\n",
    "    x_grid = np.linspace(-4, 4, 200)\n",
    "    ax.hist(vec_log * np.sqrt(N), bins=50, density=True, alpha=0.7, label='Components')\n",
    "    ax.plot(x_grid, norm.pdf(x_grid), 'r--', lw=2, label='Gaussian Theory')\n",
    "    ax.set_title('c) Components of $v_i$ (Logarithmic)', fontsize=14)\n",
    "    ax.set_xlabel(r'Components $v_i \\sqrt{N}$')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.text(\n",
    "        0.05, 0.95,\n",
    "        f'KS p-value: {ks_log.pvalue:.2f}',\n",
    "        transform=ax.transAxes,\n",
    "        ha='left', va='top',\n",
    "        color='green'\n",
    "    )\n",
    "    ax.legend()\n",
    "\n",
    "    # d) Participation Ratio\n",
    "    ax = axes[1, 1]\n",
    "    ax.hist(pr_log / N, bins=50, density=True, alpha=0.7, label='PR/N')\n",
    "    mean_pr_log = np.mean(pr_log / N)\n",
    "    ax.axvline(mean_pr_log, color='red', ls='--', label=f'Mean = {mean_pr_log:.3f}')\n",
    "    ax.axvline(1/3, color='green', ls=':', lw=3, label='GOE Theory ≈ 0.333')\n",
    "    ax.set_title('d) Participation Ratio (Logarithmic)', fontsize=14)\n",
    "    ax.set_xlabel('PR / N')\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Interactive widget ---\n",
    "interact(\n",
    "    eigenvector_analysis_lab,\n",
    "    N=widgets.Dropdown(options=[512, 1024, 2048], value=1024, description='N:'),\n",
    "    log_X0=widgets.IntSlider(\n",
    "        min=5, max=8, step=1, value=7,\n",
    "        description='X₀ = 10^',\n",
    "        continuous_update=False\n",
    "    )\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad63d49-bcec-4905-8e8c-87da0df93895",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Analysis of the Results: Genuine Signal and Artefact\n",
    "\n",
    "At first sight, the results obtained in the eigenvector laboratory appear paradoxical. This paradox, however, does not indicate an inconsistency  \n",
    "in the method. On the contrary, it exposes with particular clarity the decisive importance of the **observational lens** employed throughout  \n",
    "this work.\n",
    "\n",
    "### Observation under the Logarithmic Scale\n",
    "\n",
    "*(The genuine signal of chaos)*\n",
    "\n",
    "* **Gaussian components (Panel c)**  \n",
    "  The histogram of the components of an eigenvector extracted from the *bulk* of the spectrum fits the theoretical Gaussian curve consistently.  \n",
    "  The Kolmogorov–Smirnov test yields a typical *p*-value of order `0.2`, well above the usual rejection threshold (`0.05`).  \n",
    "  This indicates that **there is no statistical evidence to reject the Gaussian hypothesis**, in full agreement with the predictions of Random  \n",
    "  Matrix Theory for GOE-type systems.\n",
    "\n",
    "* **Participation Ratio close to 1/3 (Panel d)**  \n",
    "  The distribution of the normalised values $\\mathrm{PR}/N$ is strongly concentrated around the theoretical value `1/3`, with empirical means close to  \n",
    "  this reference (for example, `≈ 0.32`).  \n",
    "  This indicates that the eigenvectors are **delocalised and ergodic**, occupying the vector space in a homogeneous manner — a robust signature  \n",
    "  of quantum chaos.\n",
    "\n",
    "Together, these two independent results confirm that, under the logarithmic scale, the operator $ M $ exhibits not only spectral statistics  \n",
    "compatible with the GOE, but also the **internal eigenvector structure** expected of genuinely chaotic systems.\n",
    "\n",
    "---\n",
    "\n",
    "### Observation under the Linear Scale\n",
    "\n",
    "*(The “ghost in the machine”)*\n",
    "\n",
    "* **“Perfectly” Gaussian components (Panel a)**  \n",
    "  In an apparently counterintuitive manner, the KS test applied to the eigenvector components in the linear scale often produces even higher  \n",
    "  *p*-values (for example, `≈ 0.7`).  \n",
    "  Taken in isolation, this could suggest an even stronger form of chaos.\n",
    "\n",
    "* **High Participation Ratio (Panel b)**  \n",
    "  The mean value of PR/N also approaches `1/3`, a value typical of fully delocalised vectors.\n",
    "\n",
    "Taken together, these observations give rise to an apparent paradox.\n",
    "\n",
    "---\n",
    "\n",
    "### Resolving the paradox: the role of *jitter*\n",
    "\n",
    "In the linear scale, the matrix $ M $ constructed from $ \\Delta_\\pi(x) $ is structurally poor and highly degenerate.  \n",
    "To make the numerical problem tractable, it becomes necessary to introduce a minimal random perturbation (*jitter*).\n",
    "\n",
    "The effect of this perturbation is decisive:\n",
    "\n",
    "> the eigenvectors come to reflect predominantly the statistical properties of the injected noise, rather than the underlying arithmetic  \n",
    "> structure of the primes.\n",
    "\n",
    "A generic random vector possesses, by construction:\n",
    "\n",
    "* approximately Gaussian components;\n",
    "* a Participation Ratio close to `1/3`.\n",
    "\n",
    "Thus, in the linear regime, what is being measured is **an artefact of the regularisation procedure**, not a genuine physical or arithmetic signal.\n",
    "\n",
    "The contrast with the logarithmic scale is crucial. In that regime, the matrix $ M $ is already rich and complex by construction, requiring no  \n",
    "*jitter* whatsoever. Yet it displays the same signatures. This demonstrates that the GOE behaviour observed there is **intrinsic**, not  \n",
    "artificially induced.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Future Perspectives: A Cryptographic Primitive?\n",
    "\n",
    "The spectral and eigenvector properties observed in this work suggest applications that extend beyond purely theoretical analysis, including  \n",
    "possible connections to cryptography.\n",
    "\n",
    "Modern cryptography is founded on mathematical problems that are computationally easy in one direction but extremely difficult to invert — such  \n",
    "as the factorisation of large integers.\n",
    "\n",
    "The results of this chapter point towards the possibility of a **quantum-chaos-inspired cryptographic primitive**:\n",
    "\n",
    "* **Central idea**  \n",
    "  The system parameters — the initial point $ X_0 $, the dimension $ N $, and the functional $ \\Delta_\\pi(x) $ — could act as a  \n",
    "  **private key**.\n",
    "  From these parameters, it is computationally straightforward to generate specific eigenvectors of the matrix $ M $.\n",
    "\n",
    "* **Potential security**  \n",
    "  These eigenvectors are mathematical objects of extremely high complexity, with pseudo-random structure and extreme sensitivity to the  \n",
    "  initial parameters.\n",
    "  The inverse problem — reconstructing $ X_0 $ or the underlying arithmetic structure from a single eigenvector — appears, at first sight,  \n",
    "  computationally intractable.\n",
    "\n",
    "* **“Quantum” character**  \n",
    "  The “quantum” nature of this proposal does not lie in the use of quantum hardware, but in the fact that the **statistics involved coincide  \n",
    "  with those observed in chaotic quantum systems**, as described by the Montgomery–Odlyzko law.\n",
    "\n",
    "These possibilities are not pursued further in the present work, but they point towards a promising direction: the direct instrumentalisation  \n",
    "of the mathematics of quantum chaos, emerging from number theory, in concrete technological applications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
